{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5cac549-0aca-473b-9f36-8c07ebbfeb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gae import GAE, graph_embed\n",
    "from utils import GraphData, obtain_ID, convert_label_integer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eecd4e1-9854-40a4-890d-18eede13bee2",
   "metadata": {},
   "source": [
    "# Load Malware Graphs\n",
    "- There is only one processed CFG in data/examples/outputs/cfg to reduce time required by running the code, but in practice, you can have as many as processed CFGs stored in the path and our code is able to load them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee70c579-69e0-4077-9e8d-86101cbed0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  '../data/examples/outputs/cfg_node_embeddings'\n",
    "malware = GraphData(path) \n",
    "#convert one hot encoding to integer\n",
    "malware = convert_label_integer(malware)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff131dc-7791-4908-af93-ef3fd85a61da",
   "metadata": {},
   "source": [
    "# Training a graph autoencoder to generate graph embedding (Section IV.A in the main paper)\n",
    "- After training the graph autoencoder on graph $G = (X, A)$, we derive the graph representation $Z$ from the encoder: $Z = GCN (X, A)$, and then retrain the graph autoencoder from scratch for the next graph to get its graph representation.\n",
    "- To simplify the amount of work for testing, we demonstrate with just one processed graph, but the code is designed to process many graphs stored in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8560cbeb-03ff-4c15-a935-7d34cc85d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 12:56:55.770748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:55.801165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:55.802106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:55.812801: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 12:56:55.813512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:55.814646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:55.815539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:56.328648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:56.329584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:56.330437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-09-25 12:56:56.331252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21471 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-09-25 12:56:58.064665: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 66.6, AP: 65.2\n",
      "processed graph 0, status is True\n",
      "AUC: 45.0, AP: 49.7\n",
      "processed graph 1, status is True\n",
      "AUC: 44.4, AP: 53.3\n",
      "processed graph 2, status is True\n",
      "AUC: 57.8, AP: 64.5\n",
      "processed graph 3, status is True\n",
      "AUC: 70.6, AP: 68.2\n",
      "processed graph 4, status is True\n",
      "AUC: 65.9, AP: 68.2\n",
      "processed graph 5, status is True\n",
      "Complete! There are 0 failed graphs\n"
     ]
    }
   ],
   "source": [
    "# Getting the list of asm_id when loading the CFGs from the path\n",
    "# When we obtain the embedding for each graph, we will save the feature with its asm_id and the orginal label\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "file_list_x_y = list(filter(lambda x: '_sparse_matrix' not in x and '.npz' in x, file_list))\n",
    "        \n",
    "\n",
    "obtain_id= obtain_ID(path, file_list_x_y) \n",
    "file_list = obtain_id.read()\n",
    "file_list = [x.split(\"_\")[2].split(\".\")[0] for x in file_list]\n",
    "\n",
    "\n",
    "# This is where the graph embedding Z is stored \n",
    "# The next step is to run the concesus clustering on these graph embeddings to find the new cluster labels\n",
    "# Please go to concensus_clusering.ipynb  for the next step\n",
    "store_path = '../data/examples/outputs/graph_embedding'\n",
    "\n",
    "\n",
    "i = 0\n",
    "fail = 0\n",
    "for g in malware:\n",
    "    save_path = 'graph_{}_feature'.format(i)\n",
    "    filename = os.path.join(store_path, save_path)\n",
    "    try:\n",
    "        feature = tf.reshape(graph_embed(g), [-1])\n",
    "        success = True\n",
    "        asm_id  = file_list[i]\n",
    "    except Exception as e: \n",
    "        feature = []\n",
    "        success = False\n",
    "        asm_id = []\n",
    "        fail +=1\n",
    "        \n",
    "    np.savez(filename, feature = feature, success =success, asm_id = asm_id, y = g.y)\n",
    "    print(\"processed graph {}, status is {}\".format(i,success))\n",
    "    i+=1\n",
    "    \n",
    "print(\"Complete! There are {} failed graphs\".format(fail))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b8878-4176-422a-9d75-ca87030d5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ipykernel",
   "language": "python",
   "name": "ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
